{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = pd.read_csv(\"../sample_data/census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data['income_bracket'] = census_data['income_bracket'].apply(\n",
    "    lambda x: 0 if x == ' <=50K' else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = census_data.drop('income_bracket', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = census_data['income_bracket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_features, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  \n",
       "0             0              40   United-States  \n",
       "1             0              13   United-States  \n",
       "2             0              40   United-States  \n",
       "3             0              40   United-States  \n",
       "4             0              40            Cuba  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=500)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=500)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=500)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=500)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship', hash_bucket_size=500)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket('race', hash_bucket_size=500)\n",
    "gender = tf.feature_column.categorical_column_with_hash_bucket('gender', hash_bucket_size=500)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    workclass,\n",
    "    education,\n",
    "    marital_status,\n",
    "    occupation,\n",
    "    relationship,\n",
    "    race,\n",
    "    gender,\n",
    "    native_country,\n",
    "    age,\n",
    "    education_num,\n",
    "    capital_gain,\n",
    "    capital_loss,\n",
    "    hours_per_week\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=150,\n",
    "    num_epochs=1000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12e295630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feat_cols,\n",
    "    n_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp/model.ckpt.\n",
      "INFO:tensorflow:loss = 103.9721, step = 1\n",
      "INFO:tensorflow:global_step/sec: 144.994\n",
      "INFO:tensorflow:loss = 364.69693, step = 101 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.311\n",
      "INFO:tensorflow:loss = 273.15536, step = 201 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.945\n",
      "INFO:tensorflow:loss = 485.07968, step = 301 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.189\n",
      "INFO:tensorflow:loss = 196.00946, step = 401 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.496\n",
      "INFO:tensorflow:loss = 159.26112, step = 501 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.709\n",
      "INFO:tensorflow:loss = 74.97204, step = 601 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.34\n",
      "INFO:tensorflow:loss = 46.38848, step = 701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.414\n",
      "INFO:tensorflow:loss = 144.39896, step = 801 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.32\n",
      "INFO:tensorflow:loss = 151.96468, step = 901 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.595\n",
      "INFO:tensorflow:loss = 416.50146, step = 1001 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.961\n",
      "INFO:tensorflow:loss = 412.9635, step = 1101 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.704\n",
      "INFO:tensorflow:loss = 139.32965, step = 1201 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.471\n",
      "INFO:tensorflow:loss = 220.69325, step = 1301 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.097\n",
      "INFO:tensorflow:loss = 95.508896, step = 1401 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.698\n",
      "INFO:tensorflow:loss = 89.11071, step = 1501 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.113\n",
      "INFO:tensorflow:loss = 297.31165, step = 1601 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.407\n",
      "INFO:tensorflow:loss = 51.132656, step = 1701 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.509\n",
      "INFO:tensorflow:loss = 276.60022, step = 1801 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.178\n",
      "INFO:tensorflow:loss = 108.26147, step = 1901 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.389\n",
      "INFO:tensorflow:loss = 80.7448, step = 2001 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.651\n",
      "INFO:tensorflow:loss = 177.3665, step = 2101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.041\n",
      "INFO:tensorflow:loss = 45.952145, step = 2201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.906\n",
      "INFO:tensorflow:loss = 79.655, step = 2301 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.857\n",
      "INFO:tensorflow:loss = 58.825275, step = 2401 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.385\n",
      "INFO:tensorflow:loss = 468.9804, step = 2501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.371\n",
      "INFO:tensorflow:loss = 549.1505, step = 2601 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.114\n",
      "INFO:tensorflow:loss = 100.42082, step = 2701 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.824\n",
      "INFO:tensorflow:loss = 262.41846, step = 2801 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.691\n",
      "INFO:tensorflow:loss = 55.564472, step = 2901 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.39\n",
      "INFO:tensorflow:loss = 102.668976, step = 3001 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.964\n",
      "INFO:tensorflow:loss = 63.052494, step = 3101 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.499\n",
      "INFO:tensorflow:loss = 71.591385, step = 3201 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.765\n",
      "INFO:tensorflow:loss = 53.56965, step = 3301 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.173\n",
      "INFO:tensorflow:loss = 86.763916, step = 3401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.245\n",
      "INFO:tensorflow:loss = 46.236443, step = 3501 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.241\n",
      "INFO:tensorflow:loss = 114.12173, step = 3601 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.804\n",
      "INFO:tensorflow:loss = 64.747925, step = 3701 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.033\n",
      "INFO:tensorflow:loss = 133.42928, step = 3801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.821\n",
      "INFO:tensorflow:loss = 47.835392, step = 3901 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.703\n",
      "INFO:tensorflow:loss = 152.79419, step = 4001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.645\n",
      "INFO:tensorflow:loss = 93.33931, step = 4101 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.183\n",
      "INFO:tensorflow:loss = 36.769516, step = 4201 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.707\n",
      "INFO:tensorflow:loss = 99.76845, step = 4301 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.061\n",
      "INFO:tensorflow:loss = 47.506844, step = 4401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.573\n",
      "INFO:tensorflow:loss = 93.58299, step = 4501 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.309\n",
      "INFO:tensorflow:loss = 62.101772, step = 4601 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.237\n",
      "INFO:tensorflow:loss = 116.52814, step = 4701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.437\n",
      "INFO:tensorflow:loss = 60.700253, step = 4801 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.83\n",
      "INFO:tensorflow:loss = 99.0712, step = 4901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.517\n",
      "INFO:tensorflow:loss = 64.16512, step = 5001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.279\n",
      "INFO:tensorflow:loss = 81.37094, step = 5101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.714\n",
      "INFO:tensorflow:loss = 45.109722, step = 5201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.326\n",
      "INFO:tensorflow:loss = 53.205387, step = 5301 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.456\n",
      "INFO:tensorflow:loss = 111.10019, step = 5401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.591\n",
      "INFO:tensorflow:loss = 56.494453, step = 5501 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.874\n",
      "INFO:tensorflow:loss = 246.11768, step = 5601 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.256\n",
      "INFO:tensorflow:loss = 53.854996, step = 5701 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.117\n",
      "INFO:tensorflow:loss = 59.79531, step = 5801 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.558\n",
      "INFO:tensorflow:loss = 70.93828, step = 5901 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.797\n",
      "INFO:tensorflow:loss = 213.91843, step = 6001 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 51.78984, step = 6101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.484\n",
      "INFO:tensorflow:loss = 149.35916, step = 6201 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.448\n",
      "INFO:tensorflow:loss = 74.27126, step = 6301 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.557\n",
      "INFO:tensorflow:loss = 68.69621, step = 6401 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.379\n",
      "INFO:tensorflow:loss = 77.45323, step = 6501 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.85\n",
      "INFO:tensorflow:loss = 60.631523, step = 6601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.683\n",
      "INFO:tensorflow:loss = 47.23418, step = 6701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.228\n",
      "INFO:tensorflow:loss = 77.6514, step = 6801 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.713\n",
      "INFO:tensorflow:loss = 33.54296, step = 6901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.013\n",
      "INFO:tensorflow:loss = 70.860435, step = 7001 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.903\n",
      "INFO:tensorflow:loss = 86.89827, step = 7101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.822\n",
      "INFO:tensorflow:loss = 142.08116, step = 7201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.041\n",
      "INFO:tensorflow:loss = 142.4692, step = 7301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.63\n",
      "INFO:tensorflow:loss = 59.055912, step = 7401 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.512\n",
      "INFO:tensorflow:loss = 43.50801, step = 7501 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.904\n",
      "INFO:tensorflow:loss = 51.67328, step = 7601 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.999\n",
      "INFO:tensorflow:loss = 60.852615, step = 7701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.412\n",
      "INFO:tensorflow:loss = 116.554474, step = 7801 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.653\n",
      "INFO:tensorflow:loss = 89.26497, step = 7901 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.052\n",
      "INFO:tensorflow:loss = 54.601295, step = 8001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.285\n",
      "INFO:tensorflow:loss = 58.555534, step = 8101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.608\n",
      "INFO:tensorflow:loss = 122.90404, step = 8201 (0.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.817\n",
      "INFO:tensorflow:loss = 69.95195, step = 8301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.21\n",
      "INFO:tensorflow:loss = 89.24488, step = 8401 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.01\n",
      "INFO:tensorflow:loss = 99.171555, step = 8501 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.333\n",
      "INFO:tensorflow:loss = 44.1867, step = 8601 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.76\n",
      "INFO:tensorflow:loss = 48.672325, step = 8701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.98\n",
      "INFO:tensorflow:loss = 81.03898, step = 8801 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.063\n",
      "INFO:tensorflow:loss = 44.79827, step = 8901 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.538\n",
      "INFO:tensorflow:loss = 51.22359, step = 9001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.142\n",
      "INFO:tensorflow:loss = 90.27949, step = 9101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.64\n",
      "INFO:tensorflow:loss = 43.084045, step = 9201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.671\n",
      "INFO:tensorflow:loss = 58.708668, step = 9301 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.193\n",
      "INFO:tensorflow:loss = 48.39156, step = 9401 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.806\n",
      "INFO:tensorflow:loss = 143.22285, step = 9501 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.617\n",
      "INFO:tensorflow:loss = 82.219505, step = 9601 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.217\n",
      "INFO:tensorflow:loss = 52.551384, step = 9701 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.41\n",
      "INFO:tensorflow:loss = 124.81301, step = 9801 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.603\n",
      "INFO:tensorflow:loss = 141.29826, step = 9901 (0.437 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 57.34471.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x12e2951d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_test,\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_eval_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_train,\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/phil/.local/share/virtualenvs/neural_networks-7dtejGdV/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "y_pred = [prediction['class_ids'][0] for prediction in model.predict(eval_fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/rg/qlb5htps7fg440bjyl_5vztc0000gn/T/tmp0fe51utp/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "y_training_pred = [prediction['class_ids'][0] for prediction in model.predict(training_eval_fn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      6208\n",
      "           1       0.72      0.59      0.65      1933\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      8141\n",
      "   macro avg       0.80      0.76      0.78      8141\n",
      "weighted avg       0.84      0.85      0.84      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90     18512\n",
      "           1       0.75      0.57      0.65      5908\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     24420\n",
      "   macro avg       0.81      0.75      0.78     24420\n",
      "weighted avg       0.84      0.85      0.84     24420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_training_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not overfitting, b/c our training data comes back with around the same precision as our testing data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
